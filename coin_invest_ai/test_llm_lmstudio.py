"""
LM Studio API ì„œë²„ë¥¼ í†µí•œ LLM í…ŒìŠ¤íŠ¸
"""

import requests
import json

def test_lmstudio_api():
    """LM Studio API ì„œë²„ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("LM Studio API ì„œë²„ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # LM Studio ê¸°ë³¸ URL
    base_url = "http://localhost:1234/v1"
    
    # 1. API ì„œë²„ ì—°ê²° í™•ì¸
    print(f"\n1. LM Studio API ì„œë²„ ì—°ê²° í™•ì¸...")
    try:
        response = requests.get(f"{base_url}/models", timeout=5)
        if response.status_code == 200:
            models = response.json()
            print(f"   âœ… API ì„œë²„ ì—°ê²° ì„±ê³µ!")
            if 'data' in models and len(models['data']) > 0:
                print(f"   ë¡œë“œëœ ëª¨ë¸:")
                for model in models['data']:
                    print(f"      - {model.get('id', 'Unknown')}")
            else:
                print(f"   âš ï¸  ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"   âŒ API ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"   âŒ LM Studio API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print(f"   ğŸ’¡ LM Studioë¥¼ ì‹¤í–‰í•˜ê³  API ì„œë²„ë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”.")
        print(f"   ğŸ’¡ LM Studio > Settings > Server > Enable API Server")
        return False
    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    # 2. ì±„íŒ… ì™„ì„± í…ŒìŠ¤íŠ¸
    print(f"\n2. ì±„íŒ… ì™„ì„± í…ŒìŠ¤íŠ¸...")
    try:
        test_prompts = [
            "ì•ˆë…•í•˜ì„¸ìš”!",
            "ë¹„íŠ¸ì½”ì¸ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "1+1ì€ ì–¼ë§ˆì¸ê°€ìš”?"
        ]
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\n   í…ŒìŠ¤íŠ¸ {i}: {prompt}")
            
            payload = {
                "model": "local-model",  # LM StudioëŠ” ë¡œì»¬ ëª¨ë¸ ì´ë¦„ì„ ì‚¬ìš©
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 256
            }
            
            response = requests.post(
                f"{base_url}/chat/completions",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    content = result['choices'][0]['message']['content']
                    print(f"   âœ… ì‘ë‹µ:")
                    print(f"   {content[:200]}{'...' if len(content) > 200 else ''}")
                else:
                    print(f"   âŒ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
            else:
                print(f"   âŒ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                print(f"   ì‘ë‹µ: {response.text}")
                
    except Exception as e:
        print(f"   âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print(f"\n" + "=" * 60)
    print("âœ… LM Studio API í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
    return True


if __name__ == "__main__":
    test_lmstudio_api()

